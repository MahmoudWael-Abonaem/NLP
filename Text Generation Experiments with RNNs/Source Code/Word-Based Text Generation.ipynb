{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import wikipedia\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Wikipedia Article and Preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:33:02.349374Z",
     "iopub.status.busy": "2024-05-09T17:33:02.348437Z",
     "iopub.status.idle": "2024-05-09T17:33:02.991686Z",
     "shell.execute_reply": "2024-05-09T17:33:02.990789Z",
     "shell.execute_reply.started": "2024-05-09T17:33:02.349333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "docs = wikipedia.page(\"Egypt\")\n",
    "\n",
    "docs = re.sub(r'[^a-zA-Z\\s]', '', docs.content)  # Remove punctuation and digits\n",
    "docs = docs.lower().strip()\n",
    "docs = re.sub(r'\\s+', ' ', docs)\n",
    "words = re.findall(r'\\b\\w+\\b', docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Unique Words in the Document (Article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:33:02.994336Z",
     "iopub.status.busy": "2024-05-09T17:33:02.994009Z",
     "iopub.status.idle": "2024-05-09T17:33:03.001947Z",
     "shell.execute_reply": "2024-05-09T17:33:03.000914Z",
     "shell.execute_reply.started": "2024-05-09T17:33:02.994308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261 unique words\n"
     ]
    }
   ],
   "source": [
    "# The unique words in the document\n",
    "vocab = sorted(set(words))\n",
    "print(f'{len(vocab)} unique words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:33:03.004323Z",
     "iopub.status.busy": "2024-05-09T17:33:03.003485Z",
     "iopub.status.idle": "2024-05-09T17:33:03.014162Z",
     "shell.execute_reply": "2024-05-09T17:33:03.013183Z",
     "shell.execute_reply.started": "2024-05-09T17:33:03.004282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mapping from words to indices and vice versa\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# Convert text to sequences of word indices\n",
    "word_indices = [word_to_idx[word] for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset to Feed the Model with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:33:03.016217Z",
     "iopub.status.busy": "2024-05-09T17:33:03.015522Z",
     "iopub.status.idle": "2024-05-09T17:33:03.881988Z",
     "shell.execute_reply": "2024-05-09T17:33:03.881110Z",
     "shell.execute_reply.started": "2024-05-09T17:33:03.016181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Create sequences of word indices\n",
    "sequences = [word_indices[i:i+sequence_length+1] for i in range(len(word_indices)-sequence_length)]\n",
    "\n",
    "# Pad sequences to have the same length\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
    "\n",
    "# Convert padded_sequences to a dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((padded_sequences[:, :-1], padded_sequences[:, 1:]))\n",
    "\n",
    "# Shuffle and batch the dataset\n",
    "dataset = dataset.shuffle(buffer_size=len(sequences)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and Training the Word-Based RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:33:03.883461Z",
     "iopub.status.busy": "2024-05-09T17:33:03.883155Z",
     "iopub.status.idle": "2024-05-09T17:35:05.309245Z",
     "shell.execute_reply": "2024-05-09T17:35:05.308210Z",
     "shell.execute_reply.started": "2024-05-09T17:33:03.883435Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  3/207\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - loss: 8.0462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715275988.351917     116 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1715275988.415370     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 59ms/step - loss: 5.9373\n",
      "Epoch 2/10\n",
      "\u001b[1m  2/207\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - loss: 1.1399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1715276000.431542     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n",
      "W0000 00:00:1715276000.472133     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.6532\n",
      "Epoch 3/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.1470\n",
      "Epoch 4/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0942\n",
      "Epoch 5/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0723\n",
      "Epoch 6/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0604\n",
      "Epoch 7/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0538\n",
      "Epoch 8/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0495\n",
      "Epoch 9/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0462\n",
      "Epoch 10/10\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(vocab), output_dim=256),\n",
    "    tf.keras.layers.SimpleRNN(1024, return_sequences=True, return_state=False, recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(len(vocab))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "history = model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Word-Based Text Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:42:16.948820Z",
     "iopub.status.busy": "2024-05-09T17:42:16.948392Z",
     "iopub.status.idle": "2024-05-09T17:42:16.957505Z",
     "shell.execute_reply": "2024-05-09T17:42:16.956500Z",
     "shell.execute_reply.started": "2024-05-09T17:42:16.948782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reset the states of the model\n",
    "def reset_states(model):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'reset_states'):\n",
    "            layer.reset_states()\n",
    "\n",
    "def generate_text(model, start_string, num_generate=100, temperature=1.0):\n",
    "    input_eval = [word_to_idx[word] for word in start_string.split()]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    reset_states(model)\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0) / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx_to_word[predicted_id])\n",
    "\n",
    "    return start_string + ' '.join(text_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text Using the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T17:42:17.255604Z",
     "iopub.status.busy": "2024-05-09T17:42:17.255194Z",
     "iopub.status.idle": "2024-05-09T17:42:19.194617Z",
     "shell.execute_reply": "2024-05-09T17:42:19.193616Z",
     "shell.execute_reply.started": "2024-05-09T17:42:17.255573Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egyptis a referendum during the s giving a surprise attack on january which was invaded egypt has been competitive in the british protectorate of the ottoman turks greeks bedouin arab world the french forces had ruled egypt was forced to the establishment of the next six million egyptians represented by the egyptian deep and the gaza strip in egypt has two strands of the century egypt has been described egypt was known as the total inhabited area of the egyptian museum and alifa rifaat who had captured alexandria in the gaza strip in the largest collection of the government as\n"
     ]
    }
   ],
   "source": [
    "start_string = 'egypt'\n",
    "generated_text = generate_text(model, start_string=start_string, num_generate=100, temperature=0.6)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
